{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Input,\n",
    "    Conv2D\n",
    ")\n",
    "\n",
    "from skimage.io import imread\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.s3_class import S3Functions\n",
    "\n",
    "s3_funcs = S3Functions(bucket_name='jdgallegoq-pinacle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "print('keras version: ', keras.__version__)\n",
    "print('tensorflow version: ', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeds to stop (try) random behaviour\n",
    "seed = 42\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "DATA_PATH = 'mnist/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(s3_funcs.read_object(key=DATA_PATH+'train.csv'))\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read images\n",
    "temp = []\n",
    "for img_name in tqdm(train.filename):\n",
    "    img = s3_funcs.read_image(key=DATA_PATH+'images/'+img_name)\n",
    "    temp.append(img)\n",
    "\n",
    "train_array = np.stack(temp)\n",
    "train_array = train_array.reshape(len(train_array), -1, 784).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate if need to standardize pixels\n",
    "train_array.min(), train_array.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_size = 0.7\n",
    "split_size = int(train_array.shape[0]*train_size)\n",
    "\n",
    "x_train, x_val = train_array[:split_size], train_array[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture\n",
    "input_img = Input(shape=(784,))\n",
    "\n",
    "# --- ENCODER --- #\n",
    "encoded = Dense(2000, activation='relu')(input_img)\n",
    "encoded = Dense(500, activation='relu')(encoded)\n",
    "encoded = Dense(100, activation='relu')(encoded)\n",
    "encoded = Dense(10, activation='linear')(encoded)\n",
    "\n",
    "# --- DECODER --- #\n",
    "decoded = Dense(100, activation='relu')(encoded)\n",
    "decoded = Dense(500, activation='relu')(decoded)\n",
    "# last layer must match input shape\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "# make the model to map input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# see summaries\n",
    "print(autoencoder.summary())\n",
    "print(encoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "# remember that we're not clasifying so loss is going to be a reg function\n",
    "autoencoder.compile(optimzer='Adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "epochs = 100,\n",
    "batch_size=256\n",
    "autoencoder.fit(\n",
    "    x_train,\n",
    "    x_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_val, x_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now check how it is actually performing\n",
    "temp = autoencoder.predict(x_train)\n",
    "plt.imshow(temp[0].reshape(28, 28), cmap='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essentially, the features that are useful for downstream steps\n",
    "# are the features from the encoder (what the model really learn)\n",
    "# which are the following:\n",
    "temp = encoder.predict(x_train)\n",
    "temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so extract features from images\n",
    "pred_auto_train = encoder.predict(x_train)\n",
    "pred_auto_val = encoder.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define K-means\n",
    "kmeans = KMeans(n_jobs=-2, n_clusters=10)\n",
    "kmeans.fit(pred_auto_train)\n",
    "\n",
    "# get clusters from val data\n",
    "pred = kmeans.predict(pred_auto_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize clusters\n",
    "index = rng.choice(range(len(x_val)))\n",
    "\n",
    "print(\"This image belongs to cluster: \"+str(pred[index]))\n",
    "plt.imshow(x_val[index].reshape(28,28), cmap='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so, to get a more accurate understanding of how well it is performing\n",
    "# create a pd dataframe with labels and clusters\n",
    "y = train.label.values\n",
    "y_train, y_val = y[split_size:], y[:split_size]\n",
    "\n",
    "# compare with actual values\n",
    "temp = pd.DataFrame({\"val_y\": y_val, \"cluster_name\":pred})\n",
    "temp[temp.cluster_name==1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overral model score\n",
    "normalized_mutual_info_score(pred, val_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
